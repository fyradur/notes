#+title: Lecture 9 notes // Statistical Methods
#+author: Typeset by John MÃ¶ller
#+OPTIONS: title:nil author:t toc:nil num:t
#+LaTeX_CLASS: cleanse
#+LATEX_HEADER_EXTRA: \documentclass[10pt]{article}
#+LATEX_HEADER_EXTRA: \usepackage[T1]{fontenc}     
#+LATEX_HEADER_EXTRA: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER_EXTRA: \usepackage[swedish]{babel}
#+LATEX_HEADER_EXTRA: \usepackage{amsfonts,amsmath,amssymb}
#+LATEX_HEADER_EXTRA: \usepackage{/home/john/Documents/skola/tex/old_notestex_en}
#+LATEX:\title{{Lecture 9 notes}\\{\normalsize{\itshape Statistical Methods}}}
#+LATEX:\pagestyle{fancynotes}
#+LATEX:\maketitle
* Page 1
Minimal Variance Unbiased Estimator (MVUE):

** thm: Lehman-Schally :ignore:
#+LATEX: \begin{theorem}[Lehman-Schally] \label{thm:Lehman-Schally}
Let \( T(X_1, \dots , X_n) \) be an unbiased estimator of \( g(\theta ) \).

\begin{align*}
E(T(X_1 , \dots , X_n)) =  g(\theta )
\end{align*}
with finite variance.
T is MVUE for \( \theta  \) iff \( E(T(X_1, \dots , X_n) = S(X_1 , \dots , X_n)) =  0 \) for every \( S \) s.t. \( E(S(X_1 , \dots , X_n )) =  0 \),
\( \text{Var}(S) < \infty  \),
we can use "special estimators" ex BLUE (Best linear unbiased estimator) in lin reg MSE is usually BLUE.
CDF:
\begin{align*}
F(x) =  P( X \leq x)
\end{align*}
#+LATEX: \end{theorem}

** def: Empirical cumulative distribution function :ignore:
#+LATEX: \begin{definition}[Empirical cumulative distribution function]  \label{def:Empirical_cumulative_distribution_function}
\begin{align*}
F_n (u, (X_1, \dots , X_n)) =  n  ^{ - 1} \sum_{ i = 0 }^{ n } I  _{( - u, u)} (X_i)  &  =
\begin{cases}
0,  &  u \leq X _{(1)} \\
\frac{k}{n} X  _{(k)}  \leq u \leq  X  _{k + 1} \\
1  &  u > X  _{(n)} .
\end{cases}
\end{align*}
#+LATEX: \end{definition}

** Order statistics
\begin{align*}
X_1 , \dots , X_n  \Rightarrow X  _{(1)} \leq X _{(2)} \leq \dots \leq X  _{(n)} 
\end{align*}
[!!image 1]

*** thm: Glivenko-Conteli :ignore:
#+LATEX: \begin{theorem}[Glivenko-Conteli] \label{thm:Glivenko-Conteli}
\begin{align*}
F_n \rightarrow _{n \to \infty } F
\end{align*}
[!add type of convergence]
#+LATEX: \end{theorem}



\begin{align*}
 &  X_i \sim \text{N}(\mu , \sigma^2) \\
 &  \overline{X} \sim N(\mu  \frac{\sigma ^2 }{n} \\
 &  \frac{\overline{X} -  \mu }{\frac{\sigma}{\sqrt{n}}} \\
 &  \text{ Show: } \\
 &  \overline{X} \pm \epsilon 
\end{align*}

\begin{align*}
P( - 1.96 \leq \frac{\overline{X} - \mu }{\frac{\sigma }{\sqrt{n}}} \leq 1.96)  &  =  95 \%  / -  \frac{\sigma}{\sqrt{n}} \\
P( - 1.96  \frac{\sigma }{\sqrt{n}}\leq \overline{X} - \mu \leq 1.96 \frac{\sigma }{\sqrt{n}})  &  =  95 \%  / -  \overline{X} \\
P( - 1.96  \frac{\sigma }{\sqrt{n}} - \overline{X} \leq - \mu \leq 1.96 \frac{\sigma }{\sqrt{n}} - \overline{X})  &  =  95 \%  / -  ( - 1) \\
P( \overline{X} - 1.96  \frac{\sigma }{\sqrt{n}}  \leq  \mu \leq \overline{X} + 1.96 \frac{\sigma }{\sqrt{n}})  &  =  95 \%.
\end{align*}
*** def: Confidence Interval :ignore:
#+LATEX: \begin{definition}[Confidence Interval]  \label{def:Confidence_Interval}
A RANDOM interval \( (L,U) \)

\( [L,U] \)
[?]
is a confidence interval for parameter \( \theta  \) with confidence level \( \alpha  \) if
\begin{align*}
P(L \leq \theta \leq U) =  1 - \alpha
\end{align*}

Confidence interval \( (L,U) \) covers \( \theta  \) with \( 1 - \alpha  \) probability.
#+LATEX: \end{definition}


\begin{align*}
\overline{X} \pm z  _{\frac{\alpha}{2}} \cdot \frac{\sigma }{\sqrt{n}}
\end{align*}
is a \( \alpha  \)-level confidence interval for \( \mu  \).

Show:

*** exe:  :ignore:
#+LATEX: \begin{exercise}[]  \label{exe:}
Show
\(( - \infty , \overline{X} + Z  _{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}})   \) and
\( (\overline{X} -  Z _{\frac{\alpha}{2}} \frac{\sigma}{\sqrt{n}}, \infty) \) are also \( (1 - \alpha ) \)-confidence intervals for \( \mu  \).
#+LATEX: \end{exercise}

*** exe: 
#+LATEX: \begin{exercise}[]  \label{exe:}
Show sizes of confidence intervals.
#+LATEX: \end{exercise}



*"Statistic:"*
\( H _{\theta }  = h(\text{ data }, \theta ) \), with a known distribution.

\( P( L \leq H _{\theta } \leq U) = 1 - \alpha  \).

*Fact:*
If \( X_i \sim \text{N}(0 , 1)  \) and \( Y =  X_1 ^2 + \dots + X_n^2  \) then
\( Y \sim \chi  _{k} ^2  \) where \( k \) is the degrees of freedom.

Let \( X_i \sim \text{N}(\mu , \sigma^2)  \). Since \( \frac{X_i -  \mu }{\sigma } \sim \text{N}(0 , 1)  \) that means
\begin{align*}
\sum_{ i = 1 }^{ n } \frac{\left( X_i - \mu  \right) ^2 }{\sigma ^2 } \sim \chi ^2  _{n} .
\end{align*}

"More difficult:"
\begin{align*}
\sum_{ i = 1 }^{ n } \frac{(X_i -  \overline{X}) ^2 }{\sigma ^2 } \sim \chi  _{n - 1} ^2 .
\end{align*}


*** def: Sample Variance :ignore:
#+LATEX: \begin{definition}[Sample Variance]  \label{def:Sample_Variance}
\begin{align*}
s ^2  &  = \sum_{ i = 1 }^{ n } \frac{(X_i - \overline{X})^2 }{n - 1}
\end{align*}
#+LATEX: \end{definition}

Thus:

*** thm:  :ignore:
#+LATEX: \begin{theorem}[] \label{thm:}
\begin{align*}
\frac{n - 1}{\sigma ^2 } s^2  \sim \chi  _{n - 1} ^2 .
\end{align*}
#+LATEX: \end{theorem}

Quantile of \( \chi  _{n} ^2  \) of \( 1 - \alpha  \) level \( \chi ^2  _{\alpha } (n) \) is a point s.t.
\( P(Y \geq \chi  _{\alpha } ^2 (n)) = \alpha  \), \( Y \sim X _{n} ^2  \)

[!Insert two graphs]

[!Insert associated calculations]


*** thm:  :ignore:
#+LATEX: \begin{theorem}[] \label{thm:}
Let \( X_1, \dots , X_n \) be on i.i.d sample from \( \text{N}(\mu , \sigma^2)  \), where
\( \mu  \) and \( \delta  \) are unknow, then,
\begin{align*}
\left[ \frac{(n - 1) \cdot s^2 }{\chi  _{\frac{\alpha}{2}}(n - 1) }, \frac{(n - 1) s ^2 }{\chi  _{1 - \frac{\alpha}{2}} (n - 1)} \right] 
\end{align*}
is an \( \alpha  \)-level confidence interval for \( \sigma ^2  \).
#+LATEX: \end{theorem}

Let \( X_i \sim \text{N}(\mu , \sigma^2)  \) then
\begin{align*}
\frac{\overline{X} - \mu }{s / \sqrt{n}} \sim t(n - 1)
\end{align*}
where \( s = \sqrt{s^2 } \).

*** exe:  :ignore:
#+LATEX: \begin{exercise}[]  \label{exe:}
Show \( \overline{X} \pm t _{\alpha  / 2} (n - 1) \cdot \frac{s}{\sqrt{n}} \) is a \( 1 - \alpha  \) level quantile for \( \mu  \).
#+LATEX: \end{exercise}


** Statistical Hypothesis Testing


\begin{align*}
H_0 :  &  \mu = \mu  _{0}  \\
H_1 :  &  \mu \neq \mu  _{0} 
\end{align*}

Construct a test statistic
\begin{align*}
T = T(X_1, \dots , X_n | H_0) \sim \tilde{f}(\mu  _{0} ).
\end{align*}

\begin{align*}
X_1, \dots , X_n
\end{align*}
is a random sample

\begin{align*}
T(X_1 , \dots , X_n) \in  \text{ critical set } \theta  _{1} 
\end{align*}

If \( T \in  \theta  _{1}  \) then we reject the null hypothesis.

If \( T \not\in \theta  _{1}  \) then we fail to reject the null hypothesis.

\begin{align*}
P(T \in  \theta  _{1}  | H_0 \text{ is true }) = \alpha .
\end{align*}
 
